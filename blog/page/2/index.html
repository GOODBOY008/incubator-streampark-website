<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Blog | Apache StreamPark (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://streampark.apache.org/blog/page/2"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="Blog | Apache StreamPark (incubating)"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://streampark.apache.org/blog/page/2"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/page/2" hreflang="en"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/zh-CN/blog/page/2" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/page/2" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache StreamPark (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache StreamPark (incubating) Atom Feed"><link rel="stylesheet" href="/assets/css/styles.75eac060.css">
<link rel="preload" href="/assets/js/runtime~main.f303b739.js" as="script">
<link rel="preload" href="/assets/js/main.41b6cbdd.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?e("light"):e("dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/image/logo.png" alt="StreamPark Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/image/logo.png" alt="StreamPark Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div></a><a class="navbar__item navbar__link" href="/docs/intro">Documentation</a><a class="navbar__item navbar__link" href="/download">Download</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/foundation/policies/conduct" target="_blank" rel="noopener noreferrer" class="dropdown__link">Code of conduct</a></li><li><a class="dropdown__link" href="/community/contribution_guide/mailing_lists">Join the mailing lists</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_committer">Become A Committer</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_pmc_member">Become A PMC member</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_committer_process">New Committer Process</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_pmc_ember_process">New PMC Member Process</a></li><li><a class="dropdown__link" href="/community/submit_guide/document">Documentation Notice</a></li><li><a class="dropdown__link" href="/community/submit_guide/submit_code">Submit Code</a></li><li><a class="dropdown__link" href="/community/submit_guide/code_style_and_quality_guide">Code style and quality guide</a></li><li><a class="dropdown__link" href="/community/release/how_to_release">How to release</a></li><li><a class="dropdown__link" href="/community/release/how_to_verify_release">How to Verify Release</a></li></ul></div><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><a href="https://github.com/apache/incubator-streampark" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/blog/page/2" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-CN/blog/page/2" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-flink-on-k8s">StreamPark Flink on Kubernetes practice</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/flink-development-framework-streampark">Flink 开发利器 StreamPark</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-usercase-chinaunion">联通 Flink 实时计算平台化运维实践</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-usercase-bondex-with-paimon">海程邦达基于 Apache Paimon + StreamPark 的流式数仓实践</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-usercase-shunwang">StreamPark 在顺网科技的大规模生产实践</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-usercase-dustess">StreamPark 在尘锋信息的最佳实践，化繁为简极致体验</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-usercase-joyme">StreamPark 在 Joyme 的生产实践</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/streampark-usercase-haibo">StreamPark 一站式计算利器在海博科技的生产实践，助力智慧城市建设</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="摘要：本文源自 StreamPark 在尘锋信息的生产实践, 作者是资深数据开发工程师Gump。主要内容为："><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/streampark-usercase-dustess">StreamPark 在尘锋信息的最佳实践，化繁为简极致体验</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-10-24T15:06:09.000Z" itemprop="datePublished">October 24, 2023</time> · <!-- -->22 min read</div></header><div class="markdown" itemprop="articleBody"><p><strong>摘要：</strong>本文源自 StreamPark 在尘锋信息的生产实践, 作者是资深数据开发工程师Gump。主要内容为：</p><ol><li>技术选型</li><li>落地实践</li><li>业务支撑 &amp; 能力开放</li><li>未来规划</li><li>结束语</li></ol><p>尘锋信息是基于企业微信生态的一站式私域运营管理解决方案供应商，致力于成为全行业首席私域运营与管理专家，帮助企业构建数字时代私域运营管理新模式，助力企业实现高质量发展。</p><p>目前，尘锋已在全国拥有13个城市中心，覆盖华北、华中、华东、华南、西南五大区域，为超30个行业的10,000+家企业提供数字营销服务。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="01-技术选型"><strong>01 技术选型</strong><a href="#01-技术选型" class="hash-link" aria-label="Direct link to 01-技术选型" title="Direct link to 01-技术选型">​</a></h2><p>尘锋信息在2021年进入了快速发展时期，随着服务行业和企业客户的增加，实时需求越来越多，落地实时计算平台迫在眉睫。</p><p>由于公司处于高速发展期，需求紧迫且变化快，所以团队的技术选型遵循以下原则:</p><ul><li>快：由于业务紧迫，我们需要快速落地规划的技术选型并运用生产</li><li>稳：满足快的基础上，所选择技术一定要稳定服务业务</li><li>新：在以上基础，所选择的技术也尽量的新  </li><li>全：所选择技术能够满足公司快速发展和变化的业务，能够符合团队长期发展目标，能够支持且快速支持二次开发</li></ul><p>首先在计算引擎方面：我们选择 Flink，原因如下:</p><ul><li>团队成员对 Flink 有深入了解，熟读源码</li><li>Flink 支持批流一体，虽然目前公司的批处理架构还是基于 Hive、Spark 等。使用 Flink 进行流计算，便于后期建设批流一体和湖仓一体</li><li>目前国内 Flink 生态已经越来越成熟，Flink 也开始着手踏破边界向流式数仓发展</li></ul><p>在平台层面，我们综合对比了 StreamPark 、 Apache Zeppelin 和 flink-streaming-platform-web，也深入阅读了源码和并做了优缺点分析，关于后两个项目本文就不展开赘述，感兴趣的朋友可以去 GitHub 搜索，我们最终选择 StreamPark，理由如下：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="完成度高"><strong>完成度高</strong><a href="#完成度高" class="hash-link" aria-label="Direct link to 完成度高" title="Direct link to 完成度高">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-支持flink-多版本"><strong>1. 支持Flink 多版本</strong><a href="#1-支持flink-多版本" class="hash-link" aria-label="Direct link to 1-支持flink-多版本" title="Direct link to 1-支持flink-多版本">​</a></h4><p>//视频链接（ Flink 多版本支持 Demo ）</p><p>新建任务时可以<strong>自由选择Flink版本</strong>，Flink 二进制版本包会自动上传至 HDFS（如果使用 Yarn 提交），且一个版本的二进制包只会在 HDFS 保存一份。任务启动时会自动根据上下文加载 HDFS 中的 Flink 二进制包，非常优雅。能够满足多版本共存，及升级Flink 新版本试用测试的场景。</p><p><img loading="lazy" src="/assets/images/flink_home-0a6f4f2014cc87b074ef259088af2b98.png" width="1080" height="223" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-支持多种部署模式"><strong>2. 支持多种部署模式</strong><a href="#2-支持多种部署模式" class="hash-link" aria-label="Direct link to 2-支持多种部署模式" title="Direct link to 2-支持多种部署模式">​</a></h4><p>StreamPark 支持 Flink <strong>所有主流的提交模式</strong>，如 standalone、yarn-session 、yarn application、yarn-perjob、kubernetes-session、kubernetes-application  而且StreamPark 不是简单的拼接 Flink run 命令来进行的任务提交，而是引入了 Flink Client 源码包，直接调用 Flink Client API 来进行的任务提交。这样的好处是代码模块化、易读、便于扩展，稳定，且能在后期根据 Flink 版本升级进行很快的适配。</p><p><img loading="lazy" src="/assets/images/execution_mode-1182aeb8efe9572ec98c2a2b95293dc1.png" width="1080" height="324" class="img_ev3q"></p><p>Flink SQL 可以极大提升开发效率和提高 Flink 的普及。StreamPark 对于 <strong>Flink SQL 的支持非常到位</strong>，优秀的 SQL 编辑器，依赖管理，任务多版本管理等等。StreamPark 官网介绍后期会加入 Flink SQL 的元数据管理整合，大家拭目以待。</p><p><img loading="lazy" src="/assets/images/flink_sql-13f6952f92585140c5fc640b490918b0.png" width="1080" height="779" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/flink_sql_version-a02b0f0eac9c5d6c0281b7471e438b78.png" width="1080" height="736" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-java任务在线构建"><strong>4. JAVA任务在线构建</strong><a href="#4-java任务在线构建" class="hash-link" aria-label="Direct link to 4-java任务在线构建" title="Direct link to 4-java任务在线构建">​</a></h4><p>//视频链接（ JAVA 任务构建 Demo）</p><p>Flink SQL 现在虽然足够强大，但使用 Java 和 Scala 等 JVM 语言开发 Flink 任务会更加灵活、定制化更强、便于调优和提升资源利用率。与 SQL 相比 Jar 包提交任务最大的问题是Jar包的上传管理等，没有优秀的工具产品会严重降低开发效率和加大维护成本。 </p><p>StreamPark 除了支持 Jar 上传，更提供了<strong>在线更新构建</strong>的功能，优雅解决了以上问题：  </p><p>1、新建 Project ：填写 GitHub/Gitlab（支持企业私服）地址及用户名密码, StreamPark 就能 Pull 和 Build 项目。</p><p>2、创建 StreamPark Custom-Code 任务时引用 Project，指定主类，启动任务时可选自动 Pull、Build 和绑定生成的 Jar，非常优雅！</p><p>同时 StreamPark 社区最近也在完善整个任务编译、上线的流程，以后的 StreamPark 会在此基础上更加完善和专业。</p><p><img loading="lazy" src="/assets/images/system_list-6e9c13318d5aa2cfa4cdc11ac42c5844.png" width="1080" height="362" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="5-完善的任务参数配置"><strong>5. 完善的任务参数配置</strong><a href="#5-完善的任务参数配置" class="hash-link" aria-label="Direct link to 5-完善的任务参数配置" title="Direct link to 5-完善的任务参数配置">​</a></h4><p>对于使用 Flink 做数据开发而言，Flink run 提交的参数几乎是难以维护的。StreamPark 也非常<strong>优雅的解决</strong>了此类问题，原因是上面提到的 StreamPark 直接调用 Flink Client API，并且从 StreamPark 产品前端打通了整个流程。</p><p><img loading="lazy" src="/assets/images/parameter_configuration-94fb5d7ee0c9c04ed6d79ddb1cd3c1c7.png" width="1080" height="1001" class="img_ev3q"></p><p>大家可以看到，StreamPark 的任务参数设置涵盖了主流的所有参数，并且非常细心的对每个参数都做了介绍和最佳实践的最优推荐。这对于刚使用 Flink 的同学来说也是非常好的事情，避免踩坑！</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="6-优秀的配置文件设计"><strong>6. 优秀的配置文件设计</strong><a href="#6-优秀的配置文件设计" class="hash-link" aria-label="Direct link to 6-优秀的配置文件设计" title="Direct link to 6-优秀的配置文件设计">​</a></h4><p>对于 Flink 任务的原生参数，上面的任务参数已经涵盖了很大一部分。StreamPark 还提供了强大的<strong>Yaml 配置文件</strong> 模式和 <strong>编程模型</strong>。</p><p><img loading="lazy" src="/assets/images/extended_parameters-75c3f87809d0675c2fc82bc8d2ec096e.jpg" width="1080" height="2245" class="img_ev3q"></p><p>1、对于 Flink SQL 任务，直接使用任务的 Yaml 配置文件可以配置 StreamPark 已经内置的参数，如常见的 <strong>CheckPoint、重试机制、State Backend、table planer 、mode</strong> 等等。</p><p>2、对于 Jar 任务，StreamPark 提供了通用的编程模型，该模型封装了 Flink 原生 API ，结合 StreamPark 提供的封装包可以非常优雅的获取配置文件中的自定义参数，这块文档详见：</p><p>编程模型：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/docs/development/dev-model</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>内置配置文件参数：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/docs/development/config</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>除此之外：</p><p>StreamPark 也<strong>支持Apache Flink 原生任务</strong>，参数配置可以由 Java 任务内部代码静态维护，可以覆盖非常多的场景，比如存量 Flink 任务无缝迁移等等</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="7-checkpoint-管理"><strong>7. Checkpoint 管理</strong><a href="#7-checkpoint-管理" class="hash-link" aria-label="Direct link to 7-checkpoint-管理" title="Direct link to 7-checkpoint-管理">​</a></h4><p>关于 Flink 的 Checkpoint（Savepoint）机制，最大的困难是维护 ，StreamPark 也非常优雅的解决此问题:</p><ul><li>StreamPark 会<strong>自动维护</strong>任务 Checkpoint 的目录及版本至系统中方便检索</li><li>当用户需要更新重启应用时，可以选择是否保存 Savepoint</li><li>重新启动任务时可选择 Checkpoint/Savepoint 从指定版本的恢复</li></ul><p>如下，开发同学能够非常直观方便的升级或处理异常任务，非常强大</p><p><img loading="lazy" src="/assets/images/checkpoint-e9edd22da076247770a0b40595626fb7.png" width="1080" height="483" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/recover-f1de53fdbe66c50b465d58d0a66050de.jpg" width="1053" height="391" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="8-完善的报警功能"><strong>8. 完善的报警功能</strong><a href="#8-完善的报警功能" class="hash-link" aria-label="Direct link to 8-完善的报警功能" title="Direct link to 8-完善的报警功能">​</a></h4><p>对于流式计算此类7*24H常驻任务来说，监控报警是非常重要的 ，StreamPark 对于此类问题也有<strong>完善的解决方案</strong>:</p><ul><li>自带基于邮件的报警方式，0开发成本，配置即可使用</li><li>得益于 StreamPark 源码优秀的模块化，可以在 Task Track 处进行代码增强，引入公司内部的 SDK 进行电话、群组等报警方式，开发成本也非常低</li></ul><p><img loading="lazy" src="/assets/images/alarm_email-fd4c9ba1995ec69b7557bd1378dce737.png" width="1009" height="1340" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="源码优秀"><strong>源码优秀</strong><a href="#源码优秀" class="hash-link" aria-label="Direct link to 源码优秀" title="Direct link to 源码优秀">​</a></h3><p>遵循技术选型原则，一个新的技术必须足够了解底层原理和架构思想后，才会考虑应用生产。在选择 StreamPark 之前，对其架构和源码进入过深入研究和阅读。发现 StreamPark 所选用的底层技术是国人非常熟悉的：MySQL、Spring Boot、Mybatis Plus、Vue 等，代码风格统一，实现优雅，注释完善，各模块独立抽象合理，使用了较多的设计模式，且代码质量很高，非常适合后期的排错及二次开发。</p><p><img loading="lazy" src="/assets/images/code_notebook-542046feb8a312b5f6c057af551421c6.png" width="1080" height="527" class="img_ev3q"></p><p>StreamPark 于 2021年11月成功被开源中国评选为GVP - Gitee「最有价值开源项目」，足以见得其质量和潜力。</p><p><img loading="lazy" src="/assets/images/certificate-2f5b95ebb0816ead327ec169c12996b6.png" width="1080" height="684" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-社区活跃"><strong>03 社区活跃</strong><a href="#03-社区活跃" class="hash-link" aria-label="Direct link to 03-社区活跃" title="Direct link to 03-社区活跃">​</a></h3><p>目前社区非常活跃，从2021年11月底落地 StreamPark (基于1.2.0-release），当时StreamPark 刚刚才被大家认识，还有一些体验上的小 Bug（不影响核心功能）。当时为了快速上线，屏蔽掉了一些功能和修复了一些小 Bug，正当准备贡献给社区时发现早已修复，这也可以看出目前社区的迭代周期非常快。以后我们公司团队也会努力和社区保持一致，将新特性快速落地，提升数据开发效率和降低维护成本。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="02-落地实践"><strong>02 落地实践</strong><a href="#02-落地实践" class="hash-link" aria-label="Direct link to 02-落地实践" title="Direct link to 02-落地实践">​</a></h2><p>StreamPark 的环境搭建非常简单，跟随官网的搭建教程可以在小时内完成搭建。目前已经支持了前后端分离打包部署的模式，可以满足更多公司的需求，而且已经有 Docker Build 相关的 PR，相信以后 StreamPark 的编译部署会更加方便快捷。相关文档如下:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/docs/user-guide/deployment</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>为了快速落地和生产使用，我们选择了稳妥的 On Yarn 资源管理模式（虽然 StreamPark 已经很完善的支持 K8S），且已经有较多公司通过 StreamPark 落地了 K8S 部署方式，大家可以参考: </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/blog/flink-development-framework-streamx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>StreamPark 整合 Hadoop 生态可以说是0成本的（前提是按照 Flink 官网将 Flink 与 Hadoop 生态整合，能够通过 Flink 脚本启动任务即可）</p><p>目前我们也正在进行 K8S 的测试及方案设计，在未来一段时间会整体迁移至 K8S</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-落地-flinksql-任务"><strong>01 落地 FlinkSQL 任务</strong><a href="#01-落地-flinksql-任务" class="hash-link" aria-label="Direct link to 01-落地-flinksql-任务" title="Direct link to 01-落地-flinksql-任务">​</a></h3><p>目前我们公司基于 Flink SQL 的任务主要为业务比较简单的实时 ETL 和计算场景，数量在10个左右，上线至今都十分稳定。</p><p><img loading="lazy" src="/assets/images/online_flinksql-ca82a6f42e04e54e9f6da2b1e391b073.png" width="1080" height="118" class="img_ev3q"></p><p>StreamPark 非常贴心的准备了 Demo SQL 任务，可以直接在刚搭建的平台上运行，从这些细节可以看出社区对用户体验非常重视。前期我们的简单任务都是通过 Flink SQL 来编写及运行，StreamPark 对于 Flink SQL 的支持得非常好，优秀的 SQL 编辑器，创新型的 POM 及 Jar 包依赖管理，可以满足非常多的 SQL 场景下的问题。</p><p>目前我们正在进行元数据层面、权限、UDF等相关的方案调研、设计等</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-落地-jar-任务"><strong>02 落地 Jar 任务</strong><a href="#02-落地-jar-任务" class="hash-link" aria-label="Direct link to 02-落地-jar-任务" title="Direct link to 02-落地-jar-任务">​</a></h3><p>由于目前团队的数据开发同学大多有 Java 和 Scala 语言基础，为了更加灵活的开发、更加透明的调优 Flink 任务及覆盖更多场景，我们也快速的落地了基于 Jar 包的构建方式。我们落地分为了两个阶段</p><p>第一阶段：<strong>StreamPark 提供了原生 Apache Flink 项目的支持</strong>，我们将存量的任务Git地址配置至 StreamPark，底层使用 Maven 打包为 Jar 包，创建 StreamPark 的 Apache Flink任务，无缝的进行了迁移。在这个过程中，StreamPark 只是作为了任务提交和状态维护的一个平台工具，远远没有使用到上面提到的其他功能。</p><p>第二阶段：第一阶段将任务都迁移至 StreamPark 上之后，任务已经在平台上运行，但是任务的配置，如 checkpoint，容错以及 Flink 任务内部的业务参数的调整都需要修改源码 push 及 build，效率十分低下且不透明。</p><p>于是，根据 StreamPark 的 QuickStart 我们快速整合了StreamPark 的编程模型，也就是StreamPark Flink 任务（对于 Apache Flink）的封装。</p><p>如：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">StreamingContext = ParameterTool + StreamExecutionEnvironment</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>StreamingContext 为 StreamPark 的封装对象 </li><li>ParameterTool 为解析配置文件后的参数对象 </li></ul><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"> String value = ParameterTool.get(&quot;${user.custom.key}&quot;) </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>StreamExecutionEnvironment 为 Apache Flink 原生任务上下文</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="03-业务支撑--能力开放"><strong>03 业务支撑 &amp; 能力开放</strong><a href="#03-业务支撑--能力开放" class="hash-link" aria-label="Direct link to 03-业务支撑--能力开放" title="Direct link to 03-业务支撑--能力开放">​</a></h2><p>目前尘锋基于 StreamPark 的实时计算平台从去年11月底上线至今，已经上线 50+ Flink 任务，其中 10+为 Flink SQL 任务，40+ 为 Jar 任务。目前主要还是数据团队内部使用，近期会将实时计算平台开放全公司业务团队使用，任务量会大量增加。</p><p><img loading="lazy" src="/assets/images/online_jar-48549248f657388c7aebc0c8491660fa.png" width="1080" height="445" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-实时数仓"><strong>01 实时数仓</strong><a href="#01-实时数仓" class="hash-link" aria-label="Direct link to 01-实时数仓" title="Direct link to 01-实时数仓">​</a></h3><p>时数仓主要是用 Jar 任务，因为模式比较通用，使用 Jar 任务可以通用化的处理大量的数据表同步和计算，甚至做到配置化同步等，我们的实时数仓主要基 Apache Doris 来存储，使用 Flink 来进行清洗计算（目标是存算分离）</p><p>使用 StreamPark 整合其他组件也是非常简单，同时我们也将 Apache Doris 和 Kafka 相关的配置也抽象到了配置文件中，大大提升了我们的开发效率和灵活度。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-能力开放"><strong>02 能力开放</strong><a href="#02-能力开放" class="hash-link" aria-label="Direct link to 02-能力开放" title="Direct link to 02-能力开放">​</a></h3><p>数据团队外的其他业务团队也有很多的流处理场景，于是我们将基于 StreamPark 的实时计算平台二次开发后，将以下能力开放全公司业务团队</p><ul><li>业务能力开放：实时数仓上游将所有业务表通过日志采集写入 Kafka，业务团队可基于 Kafka 进行业务相关开发，也可通过实时数仓（Apache Doris）进行 OLAP分析</li><li>计算能力开放：将大数据平台的服务器资源开放业务团队使用</li><li>解决方案开放：Flink 生态的成熟 Connector、Exactly Once 语义支持，可减少业务团队流处理相关的开发成本及维护成本</li></ul><p>目前 StreamPark 还不支持多业务组功能，多业务组功能会抽象后贡献社区。   </p><p><img loading="lazy" src="/assets/images/manager-07ba2a4bc979cd2dd86fc9e07384ec61.png" width="1080" height="235" class="img_ev3q">        </p><p><img loading="lazy" src="/assets/images/task_retrieval-eee86f9c0af117cbf15d2af5d528b2cc.png" width="1080" height="382" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="04-未来规划"><strong>04 未来规划</strong><a href="#04-未来规划" class="hash-link" aria-label="Direct link to 04-未来规划" title="Direct link to 04-未来规划">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-flink-on-k8s"><strong>01 Flink on K8S</strong><a href="#01-flink-on-k8s" class="hash-link" aria-label="Direct link to 01-flink-on-k8s" title="Direct link to 01-flink-on-k8s">​</a></h3><p>目前我司 Flink 任务都运行在 Yarn 上，满足当下需求，但 Flink on kubernetes 有以下优点:</p><ul><li><strong>统一运维</strong>。公司统一化运维，有专门的部门运维 K8S</li><li><strong>CPU 隔离</strong>。K8S Pod 之间 CPU 隔离，实时任务不相互影响，更加稳定</li><li><strong>存储计算分离</strong>。Flink 计算资源和状态存储分离，计算资源能够和其他组件资源进行混部，提升机器使用率</li><li><strong>弹性扩缩容</strong>。能够弹性扩缩容，更好的节省人力和物力成本</li></ul><p>目前本人也在整理和落地相关的技术架构及方案，并已在实验环境使用 StreamPark 完成了 Flink on kubernetes 的技术验证，生产落地这一目标由于有 StreamPark 的平台支持，以及社区同学的热心帮心，相信在未来不久就能达成。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-流批一体建设"><strong>02 流批一体建设</strong><a href="#02-流批一体建设" class="hash-link" aria-label="Direct link to 02-流批一体建设" title="Direct link to 02-流批一体建设">​</a></h3><p>个人认为批/流最大的区别在于算子 Task 的调度策略 和 数据在算子间的流转策略：</p><ul><li><strong>批处理</strong>上下游算子 Task 存在先后调度（上游Task结束释放资源），数据存在 Shuffle 策略（落地磁盘），缺点是时效性较低且计算无中间状态，但优点是吞吐量大，适合离线超大数据量计算。</li><li><strong>流处理</strong>上下游算子 Task 同时拉起（同时占用资源），数据通过网络在节点间流式计算，缺点是吞吐量不足，优点是时效性高及计算有中间状态，适合实时及增量计算场景。</li></ul><p>如上，个人认为选择<strong>批处理</strong>还是<strong>流处理</strong>，<strong>是数据开发针对不同数据量和不同业务场景的一种调优方式</strong>。但目前由于计算引擎和计算平台会将离线、实时区分，会造成开发及维护的撕裂，成本巨高不下。如果要实现批流一体，要实现以下几个方面：</p><ul><li>存储的统一（元数据的统一）：支持批及流的写入/读取</li><li>计算引擎的统一 ：能够使用一套 API 或 SQL 开发离线和实时任务</li><li>数据平台的统一 ：能够支持实时任务常驻，也能支持离线调度策略</li></ul><p>关于批流统一这一块，目前也正在调研、整理、感兴趣的小伙伴欢迎一块探讨项目学习。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="05-结束语"><strong>05 结束语</strong><a href="#05-结束语" class="hash-link" aria-label="Direct link to 05-结束语" title="Direct link to 05-结束语">​</a></h2><p>以上就是 StreamPark 在尘锋信息生产实践的全部分享内容，感谢大家看到这里。写这篇文章的初心是为大家带来一点 StreamPark 的生产实践的经验和参考，并且和 StreamPark 社区的小伙伴们一道，共同建设 StreamPark ，未来也准备会有更多的参与和建设。非常感谢 StreamPark 的开发者们，能够提供这样优秀的产品，足够多的细节都感受到了大家的用心。虽然目前公司生产使用的（1.2.0-release）版本，在任务分组检索，编辑返回跳页等交互体验上还有些许不足，但瑕不掩瑜，相信 StreamPark 会越来越好，<strong>也相信 StreamPark 会推动 Apache Flink 的普及</strong>。最后用 Apache Flink 社区的一句话来作为结束吧：实时即未来！</p><p><img loading="lazy" src="/assets/images/author-487ad3c1ad9a397cd4c2614f54976368.png" width="844" height="439" class="img_ev3q"></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/生产实践">生产实践</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink-sql">FlinkSQL</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="摘要： 本文带来 StreamPark 在 Joyme 中的生产实践, 作者是 Joyme 的大数据工程师秦基勇, 主要内容为:"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/streampark-usercase-joyme">StreamPark 在 Joyme 的生产实践</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-10-24T15:06:09.000Z" itemprop="datePublished">October 24, 2023</time> · <!-- -->15 min read</div></header><div class="markdown" itemprop="articleBody"><br><p><strong>摘要：</strong> 本文带来 StreamPark 在 Joyme 中的生产实践, 作者是 Joyme 的大数据工程师秦基勇, 主要内容为:</p><ul><li>遇见StreamPark</li><li>Flink Sql 作业开发</li><li>Custom code 作业开发</li><li>监控告警</li><li>常见问题</li><li>社区印象</li><li>总结</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-遇见-streampark">1 遇见 StreamPark<a href="#1-遇见-streampark" class="hash-link" aria-label="Direct link to 1 遇见 StreamPark" title="Direct link to 1 遇见 StreamPark">​</a></h2><p>遇见 StreamPark 是必然的，基于我们现有的实时作业开发模式，不得不寻找一个开源的平台来支撑我司的实时业务。我们的现状如下:</p><ul><li>编写作业打包到服务器，然后执行 Flink run 命令进行提交，过程繁琐，效率低下</li><li>Flink Sql 通过自研的老平台提交，老平台开发人员已离职，后续的代码无人维护，即便有人维护也不得不面对维护成本高的问题</li><li>其中一部分作者是 SparkStreaming 作业，两套流引擎，框架不统一，开发成本大</li><li>实时作业有 Scala 和 Java 开发，语言和技术栈不统一</li></ul><p>基于以上种种原因，我们需要一个开源平台来管理我们的实时作业，同时我们也需要进行重构，统一开发模式，统一开发语言，将项目集中管理。</p><p>第一次遇见 StreamPark 就基本确定了，我们根据官网的文档快速进行了部署安装，搭建以后进行了一些操作，界面友好，Flink 多版本支持，权限管理，作业监控等一系列功能已能较好的满足我们的需求，进一步了解到其社区也很活跃，从 1.1.0 版本开始见证了 StreamPark 功能完善的过程，开发团队是非常有追求的，相信会不断的完善。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-flink-sql-作业开发">2 Flink SQL 作业开发<a href="#2-flink-sql-作业开发" class="hash-link" aria-label="Direct link to 2 Flink SQL 作业开发" title="Direct link to 2 Flink SQL 作业开发">​</a></h2><p>Flink Sql 开发模式带来了很大的便利，对于一些简单的指标开发，只需要简单的 Sql 就可以完成，不需要写一行代码。Flink Sql 方便了很多同学的开发工作，毕竟一些做仓库的同学在编写代码方面还是有些难度。</p><p>打开 StreamPark 的任务新增界面进行添加新任务，默认 Development Mode 就是 Flink Sql 模式。直接在 Flink Sql 部分编写Sql 逻辑。</p><p>Flink Sql 部分，按照 Flink 官网的文档逐步编写逻辑 Sql 即可，对于我司来说，一般就三部分: 接入 Source ，中间逻辑处理，最后 Sink。基本上 Source 都是消费 kafka 的数据，逻辑处理层会有关联 MySQL 去做维表查询，最后 Sink 部分大多是 Es，Redis，MySQL。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-编写sql"><strong>1. 编写SQL</strong><a href="#1-编写sql" class="hash-link" aria-label="Direct link to 1-编写sql" title="Direct link to 1-编写sql">​</a></h3><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- 连接kafka</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> source_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">Data</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ROW</span><span class="token operator">&lt;</span><span class="token plain">uid STRING</span><span class="token operator">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.type&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;kafka&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.version&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;universal&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.topic&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;主题&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.properties.bootstrap.servers&#x27;</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;broker地址&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.startup-mode&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;latest-offset&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;update-mode&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;append&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;format.type&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;json&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.properties.group.id&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;消费组id&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;format.derive-schema&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;true&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- 落地表sink </span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> sink_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">uid</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> STRING</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.type&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;jdbc&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.url&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;jdbc:mysql://xxx/xxx?useSSL=false&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.username&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;username&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.password&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;password&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.table&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;tablename&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.write.flush.max-rows&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;50&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.write.flush.interval&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;2s&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;connector.write.max-retries&#x27;</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;3&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- 代码逻辑过</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> sink_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">Data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">uid  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> source_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-添加依赖"><strong>2. 添加依赖</strong><a href="#2-添加依赖" class="hash-link" aria-label="Direct link to 2-添加依赖" title="Direct link to 2-添加依赖">​</a></h3><p>关于依赖这块是 StreamPark 里特有的，在 StreamPark 中创新型的将一个完整的 Flink Sql 任务拆分成两部分组成: Sql 和 依赖, Sql 很好理解不多啰嗦, 依赖是 Sql 里需要用到的一些 Connector 的 Jar, 如 Sql 里用到了 Kafka 和 MySQL 的 Connector, 那就需要引入这两个 Connector 的依赖, 在 StreamPark 中添加依赖两种方式，一种是基于标准的 Maven pom 坐标方式，另一种是从本地上传需要的 Jar 。这两种也可以混着用，按需添加，点击应用即可， 在提交作业的时候就会自动加载这些依赖。</p><p><img loading="lazy" src="/assets/images/add_dependency-281888d96a8f3ce6e9af01efef9de643.png" width="1080" height="469" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-参数配置"><strong>3. 参数配置</strong><a href="#3-参数配置" class="hash-link" aria-label="Direct link to 3-参数配置" title="Direct link to 3-参数配置">​</a></h3><p>在任务的添加和修改页面中已经罗列了一些常用的参数设置，更多的参数设置则提供了一个 yaml 配置文件，我们这里只是设置了 checkpoint 和 savepoint 这两个配置。一是 checkpoint 的位置，二是 执行 checkpoint 的频率。其他的配置基本没有动，这部分用户可以根据自己的需要按需配置。</p><p>剩下的一些参数设置就要根据作业的具体情况去对症下药的配置了，处理的数据量大了，逻辑复杂了，可能就需要更多的内存，并行度给多一些。有时候需要根据作业的运行情况进行多次调整。</p><p><img loading="lazy" src="/assets/images/checkpoint_configuration-861a4f0439b1a0f8aade35e10e6b60c5.png" width="1080" height="610" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-动态参数设置"><strong>4. 动态参数设置</strong><a href="#4-动态参数设置" class="hash-link" aria-label="Direct link to 4-动态参数设置" title="Direct link to 4-动态参数设置">​</a></h3><p>由于我们的模式部署是 on Yarn，在动态选项配置里配置了 Yarn 的队列名称。也有一些配置了开启增量的 Checkpoint 选项和状态过期时间，基本的这些参数都可以从 Flink 的官网去查询到。之前有一些作业确实经常出现内存溢出的问题，加上增量参数和过期参数以后，作业的运行情况好多了。还有就是 Flink Sql 作业设计到状态这种比较大和逻辑复杂的情况下，我个人感觉还是用 Streaming 代码来实现比较好控制一些。</p><ul><li>-Dyarn.application.queue= yarn队列名称 </li><li>-Dstate.backend.incremental=true </li><li>-Dtable.exec.state.ttl=过期时间 </li></ul><p>完成配置以后提交，然后在 application 界面进行部署。</p><p><img loading="lazy" src="/assets/images/application_job-5518b58af2b481d7bdb36a7bae252c41.png" width="1080" height="422" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-custom-code-作业开发">3 Custom Code 作业开发<a href="#3-custom-code-作业开发" class="hash-link" aria-label="Direct link to 3 Custom Code 作业开发" title="Direct link to 3 Custom Code 作业开发">​</a></h2><p>Streaming 作业我们是使用 Flink java 进行开发，将之前 Spark scala，Flink scala，Flink java 的作业进行了重构，然后工程整合到了一起，目的就是为了维护起来方便。Custom code 作业需要提交代码到 Git，然后配置项目:</p><p><img loading="lazy" src="/assets/images/project_configuration-add3d079bba91ac4977b830d3c3fe8f7.png" width="1080" height="365" class="img_ev3q"></p><p>配置完成以后，根据对应的项目进行编译，也就完成项目的打包环节。这样后面的 Constom code 作业也可以引用。每次需要上线都需要进行编译才可以，否则只能是上次编译的代码。这里有个问题，为了安全，我司的 gitlab 账号密码都是定期更新的。这样就会导致，StreamPark 已经配置好的项目还是之前的密码，结果导致编译时从 git 里拉取项目失败，导致整个编译环节失败，针对这个问题，我们联系到社区，了解到这部分已经在后续的 1.2.1 版本中支持了项目的修改操作。</p><p><img loading="lazy" src="/assets/images/flink_system-02dee8b704254087aae900731ae47076.png" width="1080" height="214" class="img_ev3q"></p><p>新建任务，选择 Custom code ，选择 Flink 版本，选择项目以及模块 Jar 包，选择开发的应用模式为 Apache Flink (标准的 Flink 程序)，程序主函数入口类，任务的名称。</p><p><img loading="lazy" src="/assets/images/add_projectconfiguration-26b97212de577a0cbc46b59f1eceea0b.png" width="1080" height="536" class="img_ev3q"></p><p>以及任务的并行度，监控的方式等，内存大小根据任务需要进行配置。Program Args 程序的参数则根据程序需要自行定义入口参数,比如：我们统一启动类是 StartJobApp，那么启动作业就需要传入作业的 Full name 告诉启动类要去找哪个类来启动此次任务，也就是一个反射机制，作业配置完成以后同样也是 Submit 提交，然后在 application 界面部署任务。</p><p><img loading="lazy" src="/assets/images/application_interface-51c8f96e343842f32b56c3c889064cba.png" width="1080" height="500" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-监控告警">4 监控告警<a href="#4-监控告警" class="hash-link" aria-label="Direct link to 4 监控告警" title="Direct link to 4 监控告警">​</a></h2><p>StreamPark 的监控需要在 setting 模块去配置发送邮件的基本信息。</p><p><img loading="lazy" src="/assets/images/system_setting-6b5b21f22fc4a32b973ede0a5f21ebc2.png" width="1080" height="380" class="img_ev3q"></p><p>然后在任务里配置重启策略：监控在多久内几次异常，然后是报警还是重启的策略，同时发送报警要发到哪个邮箱。目前我司使用版本是 1.2.1 只支持邮件发送。</p><p><img loading="lazy" src="/assets/images/email_setting-7b8ddba6688c75cfad32f5d16e93354f.png" width="1080" height="243" class="img_ev3q"></p><p>当我们的作业出现失败的情况下，就可以接收到报警邮箱。这报警还是很好看的有木有，可以清楚看到我们的哪个作业，什么状态。也可以点击下面的具体地址进行查看。</p><p><img loading="lazy" src="/assets/images/alarm_eamil-29b2875dbfcbeb071fef815ab751786a.png" width="1080" height="1517" class="img_ev3q"></p><p>关于报警这一块目前我们基于 StreamPark 的 t_flink_app 表进行了一个定时任务的开发。为什么要这么做？因为发送邮件这种通知，大部分人可能不会去及时去看。所以我们选择监控每个任务的状态去把对应的监控信息发送我们的飞书报警群，这样可以及时发现问题去解决任务。一个简单的 python 脚本，然后配置了 crontab 去定时执行。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-常见问题">5 常见问题<a href="#5-常见问题" class="hash-link" aria-label="Direct link to 5 常见问题" title="Direct link to 5 常见问题">​</a></h2><p>关于作业的异常问题，我们归纳分析了基本分为这么几种情况:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-作业启动失败"><strong>1. 作业启动失败</strong><a href="#1-作业启动失败" class="hash-link" aria-label="Direct link to 1-作业启动失败" title="Direct link to 1-作业启动失败">​</a></h3><p>作业启动失败的问题，就是点击启动运行部署。发现起不来，这时候需要看界面的详情信息的日志。在我们的任务列表中有一个眼睛的按钮，点进去。在start logs 中会找到提交的作业日志信息，点进去查看，如果有明显的提示信息，直接解决就可以了。如果没有，就需要去查看后台部署任务的目录 logs/下面的 streamx.out，打开以后会找到启动失败的日志信息。</p><p><img loading="lazy" src="/assets/images/start_log-6ce6b3125c8693db96197193241d6807.png" width="1080" height="83" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-作业运行失败"><strong>2. 作业运行失败</strong><a href="#2-作业运行失败" class="hash-link" aria-label="Direct link to 2-作业运行失败" title="Direct link to 2-作业运行失败">​</a></h3><p>如果是任务已经起来了，但是在运行阶段失败了。这种情况表面看上去和上面的情况一样，实则完全不同，这种情况是已经将任务提交给集群了，但是任务运行不起来，那就是我们的任务自身有问题了。同样可以用上面第一种情况的排查方式打开作业的具体日志，找到任务在 yarn 上运行的信息，根据日志里记录的 yarn 的 tackurl 去 yarn 的日志里查看具体的原因，是 Sql 的 Connector 不存在，还是代码的哪行代码空指针了，都可以看到具体的堆栈信息。有了具体信息，就可以对症下药了。</p><p><img loading="lazy" src="/assets/images/yarn_log-100e18b484ec81cf3165736de8259365.png" width="1080" height="82" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-社区印象">6 社区印象<a href="#6-社区印象" class="hash-link" aria-label="Direct link to 6 社区印象" title="Direct link to 6 社区印象">​</a></h2><p>很多时候我们在 StreamPark 用户群里讨论问题，都会得到社区小伙伴的即时响应。提交的一些 issue 在当下不能解决的，基本也会在下一个版本或者最新的代码分支中进行修复。在群里，我们也看到很多不是社区的小伙伴，也在积极互相帮助去解决问题。群里也有很多其他社区的大佬，很多小伙伴也积极加入了社区的开发工作。整个社区给我的感觉还是很活跃！</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-总结">7 总结<a href="#7-总结" class="hash-link" aria-label="Direct link to 7 总结" title="Direct link to 7 总结">​</a></h2><p>目前我司线上运行 60 个实时作业，Flink sql 与 Custom-code 差不多各一半。后续也会有更多的实时任务进行上线。很多同学都会担心 StreamPark 稳不稳定的问题，就我司根据几个月的生产实践而言，StreamPark 只是一个帮助你开发作业，部署，监控和管理的一个平台。到底稳不稳，还是要看自家的 Hadoop yarn 集群稳不稳定（我们用的onyan模式），其实已经跟 StreamPark关系不大了。还有就是你写的 Flink Sql 或者是代码健不健壮。更多的是这两方面应该是大家要考虑的，这两方面没问题再充分利用 StreamPark 的灵活性才能让作业更好的运行，单从一方面说 StreamPark 稳不稳定，实属偏激。</p><p>以上就是 StreamPark 在乐我无限的全部分享内容，感谢大家看到这里。非常感谢 StreamPark 提供给我们这么优秀的产品，这就是做的利他人之事。从1.0 到 1.2.1 平时遇到那些bug都会被即时的修复，每一个issue都被认真对待。目前我们还是 onyarn的部署模式，重启yarn还是会导致作业的lost状态，重启yarn也不是天天都干的事，关于这个社区也会尽早的会去修复这个问题。相信 StreamPark 会越来越好，未来可期。</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/生产实践">生产实践</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink-sql">FlinkSQL</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="摘要：本文「 StreamPark 一站式计算利器在海博科技的生产实践，助力智慧城市建设 」作者是海博科技大数据架构师王庆焕，主要内容为："><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/streampark-usercase-haibo">StreamPark 一站式计算利器在海博科技的生产实践，助力智慧城市建设</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-10-24T15:06:09.000Z" itemprop="datePublished">October 24, 2023</time> · <!-- -->7 min read</div></header><div class="markdown" itemprop="articleBody"><p><strong>摘要：</strong>本文「 StreamPark 一站式计算利器在海博科技的生产实践，助力智慧城市建设 」作者是海博科技大数据架构师王庆焕，主要内容为：</p><ol><li>选择 StreamPark</li><li>快速上手</li><li>应用场景</li><li>功能扩展</li><li>未来期待</li></ol><p>海博科技是一家行业领先的人工智能物联网产品和解决方案公司。目前在公共安全、智慧城市、智慧制造领域，为全国客户提供包括算法、软件和硬件产品在内的全栈式整体解决方案。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="01-选择-streampark"><strong>01. 选择 StreamPark</strong><a href="#01-选择-streampark" class="hash-link" aria-label="Direct link to 01-选择-streampark" title="Direct link to 01-选择-streampark">​</a></h2><p>海博科技自 2020 年开始使用 Flink SQL 汇聚、处理各类实时物联数据。随着各地市智慧城市建设步伐的加快，需要汇聚的各类物联数据的数据种类、数据量也不断增加，导致线上维护的 Flink SQL 任务越来越多，一个专门的能够管理众多 Flink SQL 任务的计算平台成为了迫切的需求。</p><p>在体验对比了 Apache Zeppelin 和 StreamPark 之后，我们选择了 StreamPark 作为公司的实时计算平台。相比 Apache Zeppelin， StreamPark 并不出名。‍‍‍‍‍‍‍‍‍‍‍‍但是在体验了 StreamPark 发行的初版，阅读其设计文档后，我们发现其基于 <strong>一站式</strong> 设计的思想，能够覆盖 Flink 任务开发的全生命周期，使得配置、开发、部署、运维全部在一个平台即可完成。我们的开发、运维、测试的同学可以使用 StreamPark 协同工作，<strong>低代码</strong> + <strong>一站式</strong> 的设计思想坚定了我们使用 StreamPark 的信心。</p><p>//视频链接（ StreamX 官方闪屏）</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="02-落地实践"><strong>02. 落地实践</strong><a href="#02-落地实践" class="hash-link" aria-label="Direct link to 02-落地实践" title="Direct link to 02-落地实践">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-快速上手"><strong>1. 快速上手</strong><a href="#1-快速上手" class="hash-link" aria-label="Direct link to 1-快速上手" title="Direct link to 1-快速上手">​</a></h3><p>使用 StreamPark 完成一个实时汇聚任务就像把大象放进冰箱一样简单，仅需三步即可完成:</p><ul><li>编辑 SQL</li></ul><p><img loading="lazy" src="/assets/images/flink_sql-a8811954a9f765640bb08ad9cd139a15.png" width="1080" height="578" class="img_ev3q"></p><ul><li>上传依赖包</li></ul><p><img loading="lazy" src="/assets/images/dependency-172169d43c50f455fb7e2c7e08de32a2.png" width="1080" height="449" class="img_ev3q"></p><ul><li>部署运行</li></ul><p><img loading="lazy" src="/assets/images/deploy-d486a5c0eb238a9f2a6ce5f2b3013500.png" width="1080" height="538" class="img_ev3q"></p><p>仅需上述三步，即可完成 Mysql 到 Elasticsearch 的汇聚任务，大大提升数据接入效率。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-生产实践"><strong>2. 生产实践</strong><a href="#2-生产实践" class="hash-link" aria-label="Direct link to 2-生产实践" title="Direct link to 2-生产实践">​</a></h3><p>StreamPark 在海博主要用于运行实时 Flink SQL任务: 读取 Kafka 上的数据，进行处理输出至 Clickhouse 或者 Elasticsearch 中。</p><p>从2021年10月开始，公司逐渐将 Flink SQL 任务迁移至 StreamPark 平台来集中管理，承载我司实时物联数据的汇聚、计算、预警。</p><p>截至目前，StreamPark 已在多个政府、公安生产环境进行部署，汇聚处理城市实时物联数据、人车抓拍数据。以下是在某市专网部署的 StreamPark 平台截图 : </p><p><img loading="lazy" src="/assets/images/application-b12eb5d36d548a02e52ec12a28ddcec0.png" width="1080" height="613" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="03-应用场景"><strong>03. 应用场景</strong><a href="#03-应用场景" class="hash-link" aria-label="Direct link to 03-应用场景" title="Direct link to 03-应用场景">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-实时物联感知数据汇聚"><strong>1. 实时物联感知数据汇聚</strong><a href="#1-实时物联感知数据汇聚" class="hash-link" aria-label="Direct link to 1-实时物联感知数据汇聚" title="Direct link to 1-实时物联感知数据汇聚">​</a></h4><p>汇聚实时的物联感知数据，我们直接使用 StreamPark 开发 Flink SQL 任务，针对 Flink SQL 未提供的方法，StreamPark 也支持 Udf 相关功能，用户通过 StreamPark 上传 Udf 包，即可在 SQL 中调用相关 Udf，实现更多复杂的逻辑操作。</p><p>“SQL+UDF” 的方式，能够满足我们绝大部分的数据汇聚场景，如果后期业务变动，也只需要在 StreamPark 中修改 SQL 语句，即可完成业务变更与上线。</p><p><img loading="lazy" src="/assets/images/data_aggregation-e5caba8eee38a8444df6cb3382a1d978.png" width="1080" height="607" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-flink-cdc数据库同步"><strong>2. Flink CDC数据库同步</strong><a href="#2-flink-cdc数据库同步" class="hash-link" aria-label="Direct link to 2-flink-cdc数据库同步" title="Direct link to 2-flink-cdc数据库同步">​</a></h4><p>为了实现各类数据库与数据仓库之前的同步，我们使用 StreamPark 开发 Flink CDC SQL 任务。借助于 Flink CDC 的能力，实现了 Oracle 与 Oracle 之间的数据同步， Mysql/Postgresql 与 Clickhouse 之间的数据同步。</p><p><img loading="lazy" src="/assets/images/flink_cdc-318444c917eb66f591a5c75db9662e78.png" width="794" height="232" class="img_ev3q"></p><p><strong>3. 数据分析模型管理</strong></p><p>针对无法使用 Flink SQL 需要开发 Flink 代码的任务，例如: 实时布控模型、离线数据分析模型，StreamPark 提供了 Custom code 的方式, 允许用户上传可执行的 Flink Jar 包并运行。</p><p>目前，我们已经将人员，车辆等 20 余类分析模型上传至 StreamPark，交由 StreamPark 管理运行。</p><p><img loading="lazy" src="/assets/images/data_aggregation-e5caba8eee38a8444df6cb3382a1d978.png" width="1080" height="607" class="img_ev3q"></p><p><strong>综上:</strong> 无论是 Flink SQL 任务还是 Custome code 任务，StreamPark 均提供了很好的支持，满足各种不同的业务场景。 但是 StreamPark 缺少任务调度的能力，如果你需要定期调度任务， StreamPark 目前无法满足。社区成员正在努力开发调度相关的模块，在即将发布的 1.2.3 中 会支持任务调度功能，敬请期待。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="04-功能扩展"><strong>04. 功能扩展</strong><a href="#04-功能扩展" class="hash-link" aria-label="Direct link to 04-功能扩展" title="Direct link to 04-功能扩展">​</a></h2><p>Datahub 是 Linkedin 开发的一个元数据管理平台，提供了数据源管理、数据血缘、数据质量检查等功能。海博科技基于 StreamPark 和 Datahub 进行了二次开发，实现了数据表级/字段级的血缘功能。通过数据血缘功能，帮助用户检查 Flink SQL 的字段血缘关系。并将血缘关系保存至Linkedin/Datahub 元数据管理平台。</p><p>//两个视频链接（基于 StreamX 开发的数据血缘功能）</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="05-未来期待"><strong>05. 未来期待</strong><a href="#05-未来期待" class="hash-link" aria-label="Direct link to 05-未来期待" title="Direct link to 05-未来期待">​</a></h2><p>目前，StreamPark 社区的 Roadmap 显示 StreamPark 1.3.0 将迎来全新的 Workbench 体验、统一的资源管理中心 (JAR/UDF/Connectors 统一管理)、批量任务调度等功能。这也是我们非常期待的几个全新功能。</p><p>Workbench 将使用全新的工作台式的 SQL 开发风格，选择数据源即可生成 SQL，进一步提升 Flink 任务开发效率。统一的 UDF 资源中心将解决当前每个任务都要上传依赖包的问题。批量任务调度功能将解决当前 StreamPark 无法调度任务的遗憾。</p><p>下图是 StreamPark 开发者设计的原型图,敬请期待。</p><p><img loading="lazy" src="/assets/images/data_source-5f9b710b4186a08571192ae81ab350d1.png" width="830" height="518" class="img_ev3q"></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/生产实践">生产实践</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink-sql">FlinkSQL</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog"><div class="pagination-nav__label">Newer Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title"></div><ul class="footer__items clean-list"><li class="footer__item">
                  <div class="footer-left-box">
                    <div class="flex align-center footer-system">
                      <span class="system-title">About StreamPark</span>
                    </div>
                    <p>Make stream processing easier! easy-to-use streaming application development framework and operation platform</p>
                  </div>
                </li></ul></div><div class="col footer__col"><div class="footer__title">Resource</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Documentation</a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">Releases<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQ<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/apache/incubator-streampark" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issue Tracker<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/pulls" target="_blank" rel="noopener noreferrer" class="footer__link-item">Pull Requests<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Follow</div><ul class="footer__items clean-list"><li class="footer__item">
                <div class="subscribe-box">
                  <div class="d-flex align-items-center" style="margin-bottom: 30px;padding-top: 11px">
                    <div class="subscribe-input flex-fill">
                      <input class="form-control" id="email_address" maxlength="60" name="email_address" placeholder="Subscribe with us">
                    </div>
                    <div class="subscribe-submit-inner">
                      <a class="btn btn-white m-0" type="submit" href="mailto:dev-subscribe@streampark.apache.org">
                        <span><i class="fa fa-paper-plane text-white"></i></span>
                      </a>
                    </div>
                  </div>
                  <ul class="icon-bottom">
                    <li>
                      <a href="javascript:void(0)">
                        <i class="fa fa-wechat"></i>
                        <div class="wechat-dropdown"><img src="/image/join_wechat.png" alt="weChat"></div>
                      </a>
                    </li>
                    <li><a href="javascript:void(0)"><i class="fa fa-twitter"></i></a></li>
                    <li><a href="javascript:void(0)"><i class="fa fa-slack"></i></a></li>
                    <li><a href="javascript:void(0)"><i class="fa fa-facebook"></i></a></li>
                  </ul>
                </div>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">
        <div style="text-align: left;margin-top:30px">
          <div class="d-flex align-items-center">
            <div>
              <a href="https://incubator.apache.org/" class="footerLogoLink" one-link-mark="yes">
                <img src="/image/apache-incubator.svg" alt="Apache Incubator logo" class="footer__logo">
              </a>
            </div>
            <div>
              <p style="font-family: Avenir-Medium;font-size: 14px;color: #999;line-height: 25px;">
              Apache StreamPark is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
              </p>
            </div>
          </div>

          <div style="border-top: 1px solid #525252;min-height: 60px;line-height: 25px;text-align: left;font-family: Avenir-Medium;font-size: 14px;color: #999;display: flex;align-items: center;">
            <span>
              Copyright © 2022-2023 The Apache Software Foundation. Apache StreamPark, StreamPark, and its feather logo are trademarks of The Apache Software Foundation.
            </span>
          </div>
        </div></div></div></div></footer></div>
<script src="/assets/js/runtime~main.f303b739.js"></script>
<script src="/assets/js/main.41b6cbdd.js"></script>
</body>
</html>